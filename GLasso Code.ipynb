{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073eeeab-2c8f-4786-9f3e-b5ec161b28ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) Find a unified regularization parameter and output a precision matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.covariance import GraphicalLassoCV, graphical_lasso, empirical_covariance\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Define input file paths\n",
    "input_files = [\n",
    "    r\"D:\\Desktop\\GraphicalLasso\\1-39x39-Input-Output-Matrices\\2005.xlsx\",\n",
    "    r\"D:\\Desktop\\GraphicalLasso\\1-39x39-Input-Output-Matrices\\2010.xlsx\",\n",
    "    r\"D:\\Desktop\\GraphicalLasso\\1-39x39-Input-Output-Matrices\\2015.xlsx\",\n",
    "    r\"D:\\Desktop\\GraphicalLasso\\1-39x39-Input-Output-Matrices\\2020.xlsx\"\n",
    "]\n",
    "\n",
    "# Define output directory\n",
    "output_dir = r\"D:\\Desktop\\GraphicalLasso\\2-Precision-Matrices\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize dictionaries and lists for data storage\n",
    "data_dict = {}\n",
    "merged_data = []\n",
    "\n",
    "# Process each input file: clean, standardize, and prepare for alpha learning\n",
    "for file_path in input_files:\n",
    "    # Load the input-output matrix\n",
    "    df = pd.read_excel(file_path, index_col=0)\n",
    "    \n",
    "    # Clean and standardize data for alpha learning\n",
    "    df_cleaned = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df_cleaned)\n",
    "\n",
    "    # Store standardized data for merged dataset\n",
    "    year = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    merged_data.append(df_scaled)\n",
    "    # Store cleaned data for precision matrix calculation\n",
    "    data_dict[year] = df_cleaned\n",
    "\n",
    "    print(f\"‚úÖ Processed data for {year}\")\n",
    "\n",
    "# Merge data and fit GraphicalLassoCV to determine the optimal alpha\n",
    "merged_data = np.vstack(merged_data)\n",
    "model = GraphicalLassoCV(max_iter=1000, tol=1e-3)\n",
    "model.fit(merged_data)\n",
    "best_alpha = model.alpha_\n",
    "\n",
    "print(f\"\\nüéØ Optimal alpha determined: {best_alpha}\")\n",
    "print(f\"‚úÖ Model iterations: {model.n_iter_}\")\n",
    "\n",
    "# Compute precision matrix for each year and save results\n",
    "for year, df_cleaned in data_dict.items():\n",
    "    # Standardize the cleaned data\n",
    "    scaler = StandardScaler()\n",
    "    data_standardized = scaler.fit_transform(df_cleaned)\n",
    "    data_df = pd.DataFrame(data_standardized, index=df_cleaned.index, columns=df_cleaned.columns)\n",
    "\n",
    "    # Compute empirical covariance matrix with a small perturbation to ensure positive definiteness\n",
    "    emp_cov = empirical_covariance(data_df)\n",
    "    epsilon = 1e-4\n",
    "    emp_cov += epsilon * np.eye(emp_cov.shape[0])\n",
    "\n",
    "    # Try different multiples of the optimal alpha to compute the precision matrix\n",
    "    success = False\n",
    "    for factor in [1, 2, 4, 8, 16]:\n",
    "        try_alpha = best_alpha * factor\n",
    "        try:\n",
    "            covariance, precision = graphical_lasso(emp_cov, alpha=try_alpha, max_iter=500, tol=1e-3)\n",
    "            print(f\"‚úÖ {year}: Precision matrix successfully estimated with alpha={try_alpha}\")\n",
    "            success = True\n",
    "            break\n",
    "        except FloatingPointError:\n",
    "            print(f\"‚ö†Ô∏è {year}: Failed with alpha={try_alpha}, trying a larger alpha...\")\n",
    "\n",
    "    if not success:\n",
    "        raise RuntimeError(f\"‚ùå {year}: All alpha values failed, unable to estimate precision matrix\")\n",
    "\n",
    "    # Save the precision matrix to Excel\n",
    "    output_file = os.path.join(output_dir, f\"{year}-Precision-Matrix.xlsx\")\n",
    "    precision_df = pd.DataFrame(precision, index=df_cleaned.columns, columns=df_cleaned.columns)\n",
    "    precision_df.to_excel(output_file)\n",
    "    print(f\"üìÅ Precision matrix saved to: {output_file}\")\n",
    "\n",
    "print(\"\\nüéâ All files processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55af4f61-5589-4348-a3ed-a64be5858191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2)Find the optimal attenuation factor and calculate Katz-Bonacich centrality\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress convergence warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Define input and output directories\n",
    "input_dir = r\"D:\\Desktop\\GraphicalLasso\\2-Precision-Matrices\"\n",
    "output_dir = r\"D:\\Desktop\\GraphicalLasso\\3-Undirected-Graph-KB-Centrality\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List of years\n",
    "years = ['2005', '2010', '2015', '2020']\n",
    "\n",
    "# Dictionary to store alpha values\n",
    "alpha_dict = {}\n",
    "\n",
    "def calculate_best_alpha_and_katz(file_path):\n",
    "    \"\"\"Calculate the optimal alpha and return Katz-Bonacich centrality\"\"\"\n",
    "    precision_matrix = pd.read_excel(file_path, index_col=0)\n",
    "\n",
    "    # Extract non-zero, non-diagonal upper triangle elements to construct edges\n",
    "    edges = []\n",
    "    for i in range(precision_matrix.shape[0]):\n",
    "        for j in range(i + 1, precision_matrix.shape[1]):\n",
    "            if precision_matrix.iloc[i, j] != 0:\n",
    "                edges.append((precision_matrix.index[i], precision_matrix.columns[j]))\n",
    "\n",
    "    if not edges:\n",
    "        raise ValueError(\"‚ùå No valid edges found!\")\n",
    "\n",
    "    # Create an undirected graph\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    # Calculate the maximum eigenvalue (to estimate alpha)\n",
    "    max_eigenvalue = max(nx.adjacency_spectrum(G, weight=None)).real\n",
    "    alpha_candidates = np.linspace(0.1, 0.99, 20) * (1 / max_eigenvalue)\n",
    "\n",
    "    def evaluate(alpha):\n",
    "        try:\n",
    "            centrality = nx.katz_centrality(G, alpha=alpha, beta=1.0, max_iter=1000, tol=1e-6)\n",
    "            return np.std(list(centrality.values()))\n",
    "        except nx.PowerIterationFailedConvergence:\n",
    "            return np.inf\n",
    "\n",
    "    stds = [evaluate(a) for a in alpha_candidates]\n",
    "    best_index = np.argmin(stds)\n",
    "    best_alpha = alpha_candidates[best_index]\n",
    "\n",
    "    # Calculate final centrality\n",
    "    katz = nx.katz_centrality(G, alpha=best_alpha, beta=1.0, max_iter=1000, tol=1e-6)\n",
    "\n",
    "    return best_alpha, katz\n",
    "\n",
    "# Iterate through years and compute centrality\n",
    "for year in years:\n",
    "    input_path = os.path.join(input_dir, f\"{year}-Precision-Matrix.xlsx\")\n",
    "    output_path = os.path.join(output_dir, f\"KB-Centrality_{year}.xlsx\")\n",
    "\n",
    "    print(f\"\\nüìò Processing data for {year}...\")\n",
    "\n",
    "    # Calculate alpha and centrality\n",
    "    alpha, katz_centrality = calculate_best_alpha_and_katz(input_path)\n",
    "    alpha_dict[year] = alpha\n",
    "\n",
    "    # Create DataFrame and add ranking column\n",
    "    df_katz = pd.DataFrame({\n",
    "        \"Sector_Code\": list(katz_centrality.keys()),\n",
    "        \"Katz_Bonacich_Centrality\": list(katz_centrality.values()),\n",
    "    })\n",
    "\n",
    "    # Sort by centrality and assign ranks (highest centrality is rank 1)\n",
    "    df_katz = df_katz.sort_values(by=\"Katz_Bonacich_Centrality\", ascending=False)\n",
    "    df_katz[\"Rank\"] = df_katz[\"Katz_Bonacich_Centrality\"].rank(ascending=False, method=\"min\").astype(int)\n",
    "\n",
    "    # Save results to Excel\n",
    "    df_katz.to_excel(output_path, index=False)\n",
    "    print(f\"‚úÖ Katz-Bonacich centrality for {year} saved to: {output_path}\")\n",
    "    print(f\"üîç Optimal attenuation factor alpha: {alpha:.5f}\")\n",
    "\n",
    "print(\"\\nüéâ Katz-Bonacich centrality calculations completed for all years!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1695489-663a-409e-a87c-e620f76091fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3)Obtain the ranking results of Sector importance for each year\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths\n",
    "base_dir = r\"D:\\Desktop\\GraphicalLasso\\3-Undirected-Graph-KB-Centrality\"\n",
    "years = ['2005', '2010', '2015', '2020']\n",
    "file_paths = {year: os.path.join(base_dir, f\"KB-Centrality_{year}.xlsx\") for year in years}\n",
    "\n",
    "# Create an empty dictionary to store DataFrames for each year (containing only sector codes and ranks)\n",
    "rank_dfs = {}\n",
    "\n",
    "for year in years:\n",
    "    df = pd.read_excel(file_paths[year])\n",
    "    df_rank = df[[\"Sector_Code\", \"Rank\"]].copy()\n",
    "    df_rank.rename(columns={\"Rank\": year}, inplace=True)\n",
    "    rank_dfs[year] = df_rank\n",
    "\n",
    "# Sequentially merge rankings for the four years, aligning on \"Sector_Code\"\n",
    "merged_df = rank_dfs[years[0]]\n",
    "for year in years[1:]:\n",
    "    merged_df = pd.merge(merged_df, rank_dfs[year], on=\"Sector_Code\", how=\"outer\")\n",
    "\n",
    "# Sort by sector code (optional)\n",
    "merged_df = merged_df.sort_values(by=\"Sector_Code\").reset_index(drop=True)\n",
    "\n",
    "# Save to Excel\n",
    "output_path = os.path.join(base_dir, \"Sector_KB_Centrality_Rankings_Summary.xlsx\")\n",
    "merged_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Successfully generated rankings summary file: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
